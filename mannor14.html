<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Approachability in unknown games: <span>O</span>nline learning meets multi-objective optimization | COLT 2014 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Approachability in unknown games: {O}nline learning meets multi-objective optimization">

  <meta name="citation_author" content="Mannor, Shie">

  <meta name="citation_author" content="Perchet, Vianney">

  <meta name="citation_author" content="Stoltz, Gilles">

<meta name="citation_publication_date" content="2014">
<meta name="citation_conference_title" content="Proceedings of The 27th Conference on Learning Theory">
<meta name="citation_firstpage" content="339">
<meta name="citation_lastpage" content="355">
<meta name="citation_pdf_url" content="mannor14.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Approachability in unknown games: <span>O</span>nline learning meets multi-objective optimization</h1>

	<div id="authors">
	
		Shie Mannor,
	
		Vianney Perchet,
	
		Gilles Stoltz
	</div>;
	<div id="info">
		JMLR W&amp;CP 35 
		
		: 
		339–355, 2014
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		In the standard setting of approachability there are two players and a target set. The players play a repeated vector-valued game where one of them wants to have the average vector-valued payoff converge to the target set which the other player tries to exclude. We revisit the classical setting and consider the setting where the player has a preference relation between target sets: she wishes to approach the smallest (“best”) set possible given the observed average payoffs in hindsight. Moreover, as opposed to previous works on approachability, and in the spirit of online learning, we do not assume that there is a known game structure with actions for two players. Rather, the player receives an arbitrary vector-valued reward vector at every round. We show that it is impossible, in general, to approach the best target set in hindsight. We further propose a concrete strategy that approaches a non-trivial relaxation of the best-in-hindsight given the actual rewards. Our approach does not require projection onto a target set and amounts to switching between scalar regret minimization algorithms that are performed in episodes.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="mannor14.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
