<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>lil’ UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits | COLT 2014 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits">

  <meta name="citation_author" content="Jamieson, Kevin">

  <meta name="citation_author" content="Malloy, Matthew">

  <meta name="citation_author" content="Nowak, Robert">

  <meta name="citation_author" content="Bubeck, Sébastien">

<meta name="citation_publication_date" content="2014">
<meta name="citation_conference_title" content="Proceedings of The 27th Conference on Learning Theory">
<meta name="citation_firstpage" content="423">
<meta name="citation_lastpage" content="439">
<meta name="citation_pdf_url" content="jamieson14.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>lil’ UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits</h1>

	<div id="authors">
	
		Kevin Jamieson,
	
		Matthew Malloy,
	
		Robert Nowak,
	
		Sébastien Bubeck
	</div>;
	<div id="info">
		JMLR W&amp;CP 35 
		
		: 
		423–439, 2014
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		The paper proposes a novel upper confidence bound (UCB) procedure for identifying the arm with the largest mean in a multi-armed bandit game in the fixed confidence setting using a small number of total samples. The procedure cannot be improved in the sense that the number of samples required to identify the best arm is within a constant factor of a lower bound based on the law of the iterated logarithm (LIL). Inspired by the LIL, we construct our confidence bounds to explicitly account for the infinite time horizon of the algorithm. In addition, by using a novel stopping time for the algorithm we avoid a union bound over the arms that has been observed in other UCB-type algorithms. We prove that the algorithm is optimal up to constants and also show through simulations that it provides superior performance with respect to the state-of-the-art.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="jamieson14.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
