<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>On the Consistency of Output Code Based Learning Algorithms for Multiclass Learning Problems | COLT 2014 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="On the Consistency of Output Code Based Learning Algorithms for Multiclass Learning Problems">

  <meta name="citation_author" content="Ramaswamy, Harish G.">

  <meta name="citation_author" content="Srinivasan Babu, Balaji">

  <meta name="citation_author" content="Agarwal, Shivani">

  <meta name="citation_author" content="Williamson, Robert C.">

<meta name="citation_publication_date" content="2014">
<meta name="citation_conference_title" content="Proceedings of The 27th Conference on Learning Theory">
<meta name="citation_firstpage" content="885">
<meta name="citation_lastpage" content="902">
<meta name="citation_pdf_url" content="ramaswamy14.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>On the Consistency of Output Code Based Learning Algorithms for Multiclass Learning Problems</h1>

	<div id="authors">
	
		Harish G. Ramaswamy,
	
		Balaji Srinivasan Babu,
	
		Shivani Agarwal,
	
		Robert C. Williamson
	</div>;
	<div id="info">
		JMLR W&amp;CP 35 
		
		: 
		885–902, 2014
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		A popular approach to solving multiclass learning problems is to reduce them to a set of binary classification problems through some output code matrix: the widely used one-vs-all and all-pairs methods, and the error-correcting output code methods of Dietterich and Bakiri (1995), can all be viewed as special cases of this approach. In this paper, we consider the question of statistical consistency of such methods. We focus on settings where the binary problems are solved by minimizing a binary surrogate loss, and derive general conditions on the binary surrogate loss under which the one-vs-all and all-pairs code matrices yield consistent algorithms with respect to the multiclass 0-1 loss. We then consider general multiclass learning problems defined by a general multiclass loss, and derive conditions on the output code matrix and binary surrogates under which the resulting algorithm is consistent with respect to the target multiclass loss. We also consider <em>probabilistic</em> code matrices, where one reduces a multiclass problem to a set of <em>class probability labeled</em> binary problems, and show that these can yield benefits in the sense of requiring a smaller number of binary problems to achieve overall consistency. Our analysis makes interesting connections with the theory of proper composite losses (Buja et al., 2005; Reid and Williamson, 2010); these play a role in constructing the right ‘decoding’ for converting the predictions on the binary problems to the final multiclass prediction. To our knowledge, this is the first work that comprehensively studies consistency properties of output code based methods for multiclass learning.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="ramaswamy14.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
