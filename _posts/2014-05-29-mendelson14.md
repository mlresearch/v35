---
title: Learning without concentration
abstract: 'We obtain sharp bounds on the convergence rate of Empirical Risk Minimization
  performed in a convex class and with respect to the squared loss, without any boundedness
  assumptions on class members or on the target. Rather than resorting to a concentration-based
  argument, the method relies on a ‘small-ball’ assumption and thus holds for heavy-tailed
  sampling and heavy-tailed targets. Moreover, the resulting estimates scale correctly
  with the ‘noise level’ of the problem. When applied to the classical, bounded scenario,
  the method always improves the known estimates. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: mendelson14
month: 0
firstpage: 25
lastpage: 39
page: 25-39
sections: 
author:
- given: Shahar
  family: Mendelson
date: 2014-05-29
address: Barcelona, Spain
publisher: PMLR
container-title: Proceedings of The 27th Conference on Learning Theory
volume: '35'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 5
  - 29
pdf: http://proceedings.mlr.press/v35/mendelson14/mendelson14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
