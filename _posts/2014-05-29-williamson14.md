---
title: The Geometry of Losses
abstract: 'Loss functions are central to machine learning because they are the means
  by which the quality of a prediction is evaluated. Any loss that is not proper,
  or can not be transformed to be proper via a link function is inadmissible. All
  admissible losses for n-class problems can be obtained in terms of a convex body
  in \mathbbR^n.  We show this explicitly and show how some existing results simplify
  when viewed from this perspective.  This  allows the development of a rich algebra
  of losses induced by binary operations on convex bodies (that return a convex body).  Furthermore
  it allows us to define an “inverse loss” which provides a universal “substitution
  function” for the Aggregating Algorithm.  In doing so we show a formal connection
  between proper losses and norms. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: williamson14
month: 0
firstpage: 1078
lastpage: 1108
page: 1078-1108
sections: 
author:
- given: Robert C.
  family: Williamson
date: 2014-05-29
address: Barcelona, Spain
publisher: PMLR
container-title: Proceedings of The 27th Conference on Learning Theory
volume: '35'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 5
  - 29
pdf: http://proceedings.mlr.press/v35/williamson14/williamson14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
