---
title: 'New Algorithms for Learning Incoherent and Overcomplete Dictionaries '
abstract: 'In \em sparse recovery we are given a matrix A ∈\mathbbR^n\times m (“the
  dictionary”) and a vector of the form A X where X is \em sparse, and the goal is
  to recover X. This is a central notion in signal processing, statistics and machine
  learning. But in applications such as \em sparse coding, edge detection, compression
  and super resolution, the dictionary A is unknown and has to be learned from random
  examples of the form Y = AX where X is drawn from an appropriate distribution —
  this is the \em dictionary learning problem. In most settings, A is \em overcomplete:
  it has more columns than rows. This paper presents a polynomial-time algorithm for
  learning overcomplete dictionaries; the only previously known algorithm with provable
  guarantees is the recent work of Spielman et al. (2012) who who gave an algorithm
  for the undercomplete case, which is rarely the case in applications. Our algorithm
  applies to \em incoherent dictionaries which have been a central object of study
  since they were introduced in seminal work of Donoho and Huo (1999). In particular,
  a dictionary is μ-incoherent if each pair of columns has inner product at most μ/
  \sqrtn. The algorithm makes natural stochastic assumptions about the unknown sparse
  vector X, which can contain k ≤c \min(\sqrtn/μ\log n, m^1/2 - η) non-zero entries
  (for any η> 0). This is close to the best k allowable by the best sparse recovery
  algorithms  \em even if one knows the dictionary A exactly. Moreover, both the running
  time and sample complexity depend on \log 1/ε, where εis the target accuracy, and
  so our algorithms converge very quickly to the true dictionary. Our algorithm can
  also tolerate substantial amounts of noise provided it is incoherent with respect
  to the dictionary (e.g., Gaussian). In the noisy setting, our running time and sample
  complexity depend polynomially on 1/ε, and this is necessary. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: arora14
month: 0
tex_title: 'New Algorithms for Learning Incoherent and Overcomplete Dictionaries '
firstpage: 779
lastpage: 806
page: 779-806
order: 779
cycles: false
author:
- given: Sanjeev
  family: Arora
- given: Rong
  family: Ge
- given: Ankur
  family: Moitra
date: 2014-05-29
address: Barcelona, Spain
publisher: PMLR
container-title: Proceedings of The 27th Conference on Learning Theory
volume: '35'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 5
  - 29
pdf: http://proceedings.mlr.press/v35/arora14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
