---
title: 'Lipschitz Bandits: Regret Lower Bound and Optimal Algorithms'
abstract: We consider stochastic multi-armed bandit problems where the expected reward
  is a Lipschitz function of the arm, and where the set of arms is either discrete
  or continuous. For discrete Lipschitz bandits, we derive asymptotic problem specific
  lower bounds for the regret satisfied by any algorithm, and propose OSLB and CKL-UCB,
  two algorithms that efficiently exploit the Lipschitz structure of the problem.
  In fact, we prove  that OSLB is asymptotically optimal, as its asymptotic regret
  matches the lower bound. The regret analysis of our algorithms relies on a new concentration
  inequality for weighted sums of KL divergences between the empirical distributions
  of rewards and their true distributions. For continuous Lipschitz bandits, we propose
  to first discretize the action space, and then apply OSLB or CKL-UCB, algorithms
  that provably exploit the structure efficiently. This approach is shown, through
  numerical experiments, to significantly outperform existing algorithms that directly
  deal with the continuous set of arms. Finally the results and algorithms are extended
  to contextual bandits with similarities.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: magureanu14
month: 0
firstpage: 975
lastpage: 999
page: 975-999
sections: 
author:
- given: Stefan
  family: Magureanu
- given: Richard
  family: Combes
- given: Alexandre
  family: Proutiere
date: 2014-05-29
address: Barcelona, Spain
publisher: PMLR
container-title: Proceedings of The 27th Conference on Learning Theory
volume: '35'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 5
  - 29
pdf: http://proceedings.mlr.press/v35/magureanu14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
