---
title: Multiarmed Bandits With Limited Expert Advice
abstract: We consider the problem of minimizing regret in the setting of advice-efficient
  multiarmed bandits with expert advice. We give an algorithm for the setting of K
  arms and N experts out of which we are allowed to query and use only M experts’
  advice in each round, which has a regret bound of \tildeO\left(\sqrt\frac\min{K,
  M} NM T\right) after T rounds. We also prove that any algorithm for this problem
  must have expected regret at least \tildeΩ\left(\sqrt\frac\min{K, M} NMT\right),
  thus showing that our upper bound is nearly tight. This solves the COLT 2013 open
  problem of Seldin et al. (2013).
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kale14a
month: 0
firstpage: 107
lastpage: 122
page: 107-122
sections: 
author:
- given: Satyen
  family: Kale
date: 2014-05-29
address: Barcelona, Spain
publisher: PMLR
container-title: Proceedings of The 27th Conference on Learning Theory
volume: '35'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 5
  - 29
pdf: http://proceedings.mlr.press/v35/kale14a.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
