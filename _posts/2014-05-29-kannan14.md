---
title: Principal Component Analysis and Higher Correlations for Distributed Data
abstract: 'We consider algorithmic problems in the setting in which the input data
  has been partitioned arbitrarily on many servers. The goal is to compute a function
  of all the data, and the bottleneck is the communication used by the algorithm.
  We present algorithms for two illustrative problems on massive data sets: (1) computing
  a low-rank approximation of a matrix A=A^1 + A^2 + \ldots + A^s, with matrix A^t
  stored on server t and (2) computing a function of a vector a_1 + a_2 + \ldots +
  a_s, where server t has the vector a_t; this includes the well-studied special case
  of computing frequency moments and separable functions, as well as higher-order
  correlations such as the number of subgraphs of a specified type occurring in a
  graph. For both problems we give algorithms with nearly optimal communication, and
  in particular the only dependence on n, the size of the data, is in the number of
  bits needed to represent indices and words (O(\log n)). '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kannan14
month: 0
firstpage: 1040
order: 1040
lastpage: 1057
page: 1040-1057
sections: 
author:
- given: Ravi
  family: Kannan
- given: Santosh
  family: Vempala
- given: David
  family: Woodruff
date: 2014-05-29
address: Barcelona, Spain
publisher: PMLR
container-title: Proceedings of The 27th Conference on Learning Theory
volume: '35'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 5
  - 29
pdf: http://proceedings.mlr.press/v35/kannan14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
