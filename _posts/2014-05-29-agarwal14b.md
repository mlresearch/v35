---
title: Robust Multi-objective Learning with Mentor Feedback
abstract: We study decision making when each action is described by a set of objectives,
  all of which are to be maximized. During the training phase, we have access to the
  actions of an outside agent (“mentor”). In the test phase, our goal is to maximally
  improve upon the mentor’s (unobserved) actions across all objectives. We present
  an algorithm with a vanishing regret compared with the optimal possible improvement,
  and show that our regret bound is the best possible. The bound is independent of
  the number of actions, and scales only as the logarithm of the number of objectives.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: agarwal14b
month: 0
firstpage: 726
lastpage: 741
page: 726-741
sections: 
author:
- given: Alekh
  family: Agarwal
- given: Ashwinkumar
  family: Badanidiyuru
- given: Miroslav
  family: Dudík
- given: Robert E.
  family: Schapire
- given: Aleksandrs
  family: Slivkins
date: 2014-05-29
address: Barcelona, Spain
publisher: PMLR
container-title: Proceedings of The 27th Conference on Learning Theory
volume: '35'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 5
  - 29
pdf: http://proceedings.mlr.press/v35/agarwal14b.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
