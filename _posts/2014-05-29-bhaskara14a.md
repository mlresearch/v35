---
title: Uniqueness of Tensor Decompositions with Applications to Polynomial Identifiability
abstract: 'We give a robust version of the celebrated result of Kruskal on the uniqueness
  of tensor decompositions: given a tensor whose decomposition satisfies a robust
  form of Kruskal’s rank condition, we prove that it is possible to approximately
  recover the decomposition if the tensor is known up to a sufficiently small (inverse
  polynomial) error. Kruskal’s theorem has found many applications in proving the
  identifiability of parameters for various latent variable models and mixture models
  such as Hidden Markov models, topic models etc. Our robust version immediately implies
  identifiability using only polynomially many samples in many of these settings –
  an essential first step towards efficient learning algorithms. Our methods also
  apply to the “overcomplete” case, which has proved challenging in many applications.
  Given the importance of Kruskal’s theorem in the tensor literature, we expect that
  our robust version will have several applications beyond the settings we explore
  in this work. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: bhaskara14a
month: 0
firstpage: 742
order: 742
lastpage: 778
page: 742-778
sections: 
author:
- given: Aditya
  family: Bhaskara
- given: Moses
  family: Charikar
- given: Aravindan
  family: Vijayaraghavan
date: 2014-05-29
address: Barcelona, Spain
publisher: PMLR
container-title: Proceedings of The 27th Conference on Learning Theory
volume: '35'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 5
  - 29
pdf: http://proceedings.mlr.press/v35/bhaskara14a.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
