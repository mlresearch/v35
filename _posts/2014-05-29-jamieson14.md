---
title: 'lil'' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits'
abstract: 'The paper proposes a novel upper confidence bound (UCB) procedure for identifying
  the arm with the largest mean in a multi-armed bandit game in the fixed confidence
  setting using a small number of total samples.  The procedure cannot be improved
  in the sense that the number of samples required to identify the best arm is within
  a constant factor of a lower bound based on the law of the iterated logarithm (LIL).
  Inspired by the LIL, we construct our confidence bounds to explicitly account for
  the infinite time horizon of the algorithm. In addition, by using a novel stopping
  time for the algorithm we avoid a union bound over the arms that has been observed
  in other UCB-type algorithms. We prove that the algorithm is optimal up to constants
  and also show through simulations that it provides superior performance with respect
  to the state-of-the-art. '
layout: inproceedings
id: jamieson14
month: 0
firstpage: 423
lastpage: 439
page: 423-439
sections: 
author:
- given: Kevin
  family: Jamieson
- given: Matthew
  family: Malloy
- given: Robert
  family: Nowak
- given: SÃ©bastien
  family: Bubeck
date: 2014-05-29
address: Barcelona, Spain
publisher: PMLR
container-title: Proceedings of The 27th Conference on Learning Theory
volume: '35'
genre: inproceedings
issued:
  date-parts:
  - 2014
  - 5
  - 29
pdf: http://proceedings.mlr.press/v35/jamieson14/jamieson14.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
